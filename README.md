# Projet05 - SystÃ¨me de PrÃ©diction RH avec API FastAPI

Un systÃ¨me complet de prÃ©diction machine learning pour l'analyse des donnÃ©es RH, suite du Projet 04 : " cause d'attrition dans une ESN", avec une API REST dÃ©ployÃ©e via Docker.

## ğŸ¯ Objectif

Ce projet dÃ©veloppe une application d'analyse RH permettant de :
- **PrÃ©dire** le dÃ©part des employÃ©s basÃ© sur leurs donnÃ©es
- **GÃ©rer** une base de donnÃ©es des donnÃ©es RH
- **Servir** des prÃ©dictions via une API REST
- **EntraÃ®ner** et **versionner** des modÃ¨les de machine learning

## ğŸ“‹ FonctionnalitÃ©s principales

### 1. **Machine Learning**
- ModÃ¨le LogisticRegression pour la classification binaire
- Pipeline de traitement des donnÃ©es avec transformations personnalisÃ©es
- Validation croisÃ©e StratifiedKFold
- Support des donnÃ©es catÃ©goriques, numÃ©riques et binaires

### 2. **API FastAPI**
- Endpoints de prÃ©diction en temps rÃ©el
- Gestion des sessions de base de donnÃ©es
- Lifespan asynchrone pour initialisation/fermeture
- Documentation Swagger auto-gÃ©nÃ©rÃ©e

### 3. **Base de DonnÃ©es**
- Gestion SQL complÃ¨te hÃ©bergÃ© sur supabase
- Tables pour les donnÃ©es d'entrÃ©e et les prÃ©dictions
- Support PostgreSQL (prod) et SQLite (pytest)
- Scripts sql d'initialisation inclus

### 4. **Tests**
- Suite de tests pytest complÃ¨te
- Tests API, base de donnÃ©es et modÃ¨le
- Couverture de code avec pytest-cov
- Tests asynchrones avec pytest-asyncio

## ğŸš€ Installation

### PrÃ©requis
- Python >= 3.10
- PostgreSQL (optionnel, SQLite supportÃ©)
- Docker (pour containerisation)

### Installation locale

1. **Cloner le repository**
```bash
git clone <repository-url>
cd projet05_test2
```

2. **CrÃ©er un environnement virtuel**
```bash
python -m venv venv
source venv/bin/activate  # Linux/Mac
# OU
venv\Scripts\activate  # Windows
```

3. **Installer les dÃ©pendances**
```bash
pip install -r requirements.txt
```

4. **Configurer la base de donnÃ©es**
```bash
# Modifier les variables d'environnement dans .env si nÃ©cessaire
python -c "from src.utils import create_bd_base; create_bd_base()"
```

## ğŸ“¦ DÃ©pendances principales

| Paquet | Version | Utilisation |
|--------|---------|-----------|
| **FastAPI** | >=0.128.0 | Framework API web |
| **SQLAlchemy** | >=2.0.46 | ORM base de donnÃ©es |
| **scikit-learn** | >=1.8.0 | Machine Learning |
| **pandas** | >=3.0.0 | Manipulation donnÃ©es |
| **numpy** | >=2.4.1 | Calculs numÃ©riques |
| **uvicorn** | >=0.30.0 | Serveur ASGI |
| **pytest** | >=9.0.2 | Framework de tests |
| **joblib** | | SÃ©rialisation modÃ¨le |

## ğŸ“ Structure du Projet

```
projet05_test2/
â”œâ”€â”€ main.py                 # Point d'entrÃ©e de l'application FastAPI
â”œâ”€â”€ requirements.txt        # DÃ©pendances du projet
â”œâ”€â”€ pyproject.toml         # Configuration du projet
â”œâ”€â”€ pytest.ini             # Configuration pytest
â”œâ”€â”€ Dockerfile             # Pour containerisation Docker
â”‚
â”œâ”€â”€ src/                   # Code source principal
â”‚   â”œâ”€â”€ __init__.py
â”‚   â”œâ”€â”€ bdd.py            # Configuration base de donnÃ©es SQLAlchemy
â”‚   â”œâ”€â”€ models.py         # ModÃ¨les Pydantic pour validation
â”‚   â”œâ”€â”€ train.py          # Pipeline et entraÃ®nement du modÃ¨le
â”‚   â”œâ”€â”€ predict.py        # Chargement et prÃ©diction
â”‚   â””â”€â”€ utils.py          # Fonctions utilitaires
â”‚
â”œâ”€â”€ model/                 # Artefacts du modÃ¨le
â”‚   â”œâ”€â”€ ml_model.joblib   # ModÃ¨le sÃ©rialisÃ©
â”‚   â””â”€â”€ __init__.py
â”‚
â”œâ”€â”€ sql/                   # Scripts SQL
â”‚   â”œâ”€â”€ create_tables_p5_rh.sql
â”‚   â”œâ”€â”€ extrait_eval_insert.csv
â”‚   â”œâ”€â”€ extrait_sirh_insert.csv
â”‚   â””â”€â”€ extrait_sondage_insert.csv
â”‚
â”œâ”€â”€ test/                  # Suite de tests
â”‚   â”œâ”€â”€ conftest.py       # Configuration pytest (fixtures)
â”‚   â”œâ”€â”€ test_api.py       # Tests API
â”‚   â”œâ”€â”€ test_database.py  # Tests base de donnÃ©es
â”‚   â”œâ”€â”€ test_model.py     # Tests modÃ¨le ML
â”‚   â””â”€â”€ test_utils.py     # Tests utilitaires
â”‚
â””â”€â”€ htmlcov/              # Rapport de couverture de code
```

## ğŸ”§ Utilisation

### DÃ©marrer l'API en local

```bash
uvicorn main:app --reload --port 8000
```

L'API sera disponible Ã  `http://localhost:8000`
- Documentation Swagger : `http://localhost:8000/docs`
- ReDoc : `http://localhost:8000/redoc`

### EntraÃ®ner le modÃ¨le
- le script est Ã  lancer en tant que "main"
```python
from src.train import train_model
train_model()
```

### Faire une prÃ©diction

```python
from src.predict import load_model, predict

model = load_model()
prediction = predict(model, data)
```

### Tests

```bash
# ExÃ©cuter tous les tests
pytest

# Avec couverture de code
pytest --cov=src --cov-report=html

# Tests spÃ©cifiques
pytest test/test_model.py
pytest test/test_api.py -v
```

## ğŸ³ Docker

### Build et Run avec Docker

```bash
# Construire l'image
docker build -t projet05-rh .

# Lancer le conteneur
docker run -p 7860:7860 projet05-rh
```

L'API sera accessible Ã  `http://localhost:7860`

### Variables d'environnement

CrÃ©er un fichier `.env` Ã  la racine pour configurer :

```env
DATABASE_URL=postgresql://user:password@localhost/projet05
PYTHONUNBUFFERED=1
```

## ğŸ“Š ModÃ¨le de Machine Learning

### Architecture

- **Type** : Classification binaire (LogisticRegression)
- **Target** : PrÃ©diction du dÃ©part employÃ© (Oui/Non)

### Features transformÃ©es par la pipeline/class :

**CatÃ©goriques (One-Hot Encoded)**:
- `statut_marital` : MariÃ©(e), CÃ©libataire, etc.
- `departement` : Ventes, IT, RH, etc.
- `poste` : Manager, Developer, etc.
- `domaine_etude` : Informatique, Marketing, etc.

**Binaires (0/1)**:
- `genre` : M (1) / F (0)
- `heure_supplementaires` : Oui (1) / Non (0)

**NumÃ©riques**:
- `age` : Ã‚ge de l'employÃ©
- `revenu_mensuel` : Salaire mensuel

**Traitements spÃ©ciaux**:
- Transformation pourcentages (% converti en entier)
- Transformation frÃ©quences (Aucunâ†’0, Occasionnelâ†’1, Frequentâ†’2)

## ğŸ“ Endpoints API

### POST `/predict`
Obtenir une prÃ©diction pour un employÃ©

**Request**:
```json
{
  "id_employee": 999,
  "age": 35,
  "genre": "M",
  "revenu_mensuel": 5000,
  "statut_marital": "MariÃ©(e)",
  "departement": "Ventes",
  "poste": "Manager"
}
```

**Response**:
```json
{
  "prediction": 1,
  "probability": 0.72
}
```

## ğŸ§ª Tests et Couverture

- **Framework** : pytest + pytest-asyncio
- **Couverture** : Rapports HTML disponibles dans `htmlcov/`
- **Tests unitaires** : Validation des transformations, utilitaires
- **Tests intÃ©gration** : API, base de donnÃ©es
- **Tests modÃ¨le** : EntraÃ®nement et prÃ©diction

ExÃ©cuter avec couverture :
```bash
pytest --cov=src --cov-report=html
```

## ğŸ” SÃ©curitÃ©

- Validation Pydantic de tous les inputs API
- DÃ©pendances gÃ©rÃ©es par SQLAlchemy
- Support des variables d'environnement pour config sensible
- Isolation via conteneur Docker

## ğŸ“ˆ Performances

- Pipeline optimisÃ© avec transformations parallÃ©lisables
- SÃ©rialisation modÃ¨le avec joblib
- API async avec FastAPI/Uvicorn
- Gestion efficace des sessions DB

## ğŸ¤ Contribution

1. Fork le repository
2. CrÃ©er une branche feature (`git checkout -b feature/AmazingFeature`)
3. Commit les changements (`git commit -m 'Add AmazingFeature'`)
4. Push vers la branche (`git push origin feature/AmazingFeature`)
5. Ouvrir une Pull Request


## ğŸ“§ Support

Pour toute question ou problÃ¨me, veuillez ouvrir une issue dans le repository.

---

**DerniÃ¨re mise Ã  jour** : FÃ©vrier 2026
